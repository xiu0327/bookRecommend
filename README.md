# bookRecommend
To Do 앱을 응용하여 만든 도서 추천 시스템


## 결과

![스크린샷 2022-07-27 오후 10 44 49](https://user-images.githubusercontent.com/78461009/183405332-0b37a003-59fb-4921-93d0-127c1e1c535b.png)


## 개발 동기

요즘 네이버 주간 블로그 챌린지가 유행이다. "참여자 전원 포인트 지급!!!" 이라는 파격적인 보상을 내건 채 시작된 챌린지는 지금까지도 계속되고 있다. 

나는 그걸 흥미롭게 여겼다. 챌린지를 시작하기 전, 온갖 광고만 난무하던 네이버 블로그에 사람들의 일상이 차곡차곡 쌓이는 현상이. 그것도 공개적으로 ! 사람들이 자신들이 좋아하는 것을 올리고 이건 싫다, 저건 좋다, 누굴 만났다와 같은 평범한 의사표현이 나에겐 재밌는 데이터로 느껴졌다.

나는 평소 책을 즐겨 읽는다. 개발 서적을 읽을 때도 있고, 소설이나 에세이, 간혹 인문 책을 읽기도 한다. 취준생인지라 매번 책을 사서 읽기 부담스러워 도서관을 자주 방문하는 편이다. 빌리고 싶은 책이 없어도 도서관 신간 도서를 구경하기 위해 발걸음하곤 한다. 

그날도 여느 날과 다름 없이 도서관에서 신간 도서를 구경하고 있었다. 시부터 시작하여 에세이까지 몇번이고 책을 뒤적였지만 마땅한 것이 보이지 않았다. 

그러다 문득 이런 생각이 들었다.

네이버 블로그로 사람들의 취향을 파악하여 그에 맞는 도서를 추천해주면 어떨까?


## 개발 과정 - 백엔드

### 1. 데이터 수집


처음엔 도서관 소장 도서로 서비스를 구축하고자 했다. 하지만 그러기엔 전국 도서관의 수가 너무 많았고, 소장 도서를 개인이 다루기엔 데이터 사이즈가 너무 컸다. 

고민 끝에, 추천 대상이 될 도서는 예스 24에서 각 카테고리 별 신간 도서를 웹 크롤링을 통해 수집했다. 수집한 데이터를 정제하여 JSON 파일로 저장했다. 

![스크린샷 2022-08-08 오후 8 09 04](https://user-images.githubusercontent.com/78461009/183406817-0e72f9c3-b584-4e65-935f-2eb38dbf2785.png)

수집한 데이터는 책 제목, 책 저자, 예스 24 링크, 책 카테고리, 책 이미지, 책 소개(konlpy Okt로 명사추출한 Token)이다. 

### 2. 네이버 블로그 키워드 추출

네이버 블로그는 동적 크롤링으로 데이터를 수집했다. 네이버 블로그마다 적용된 테마가 달라서 크롤링하기 좀 까다로워 모바일 버전으로 전환한 뒤, 모바일 웹에서 크롤링을 했다. 

키워드 알고리즘은 'KR-WordRank' 알고리즘이다. 토크나이저를 이용하지 않아도 키워드를 추출할 수 있는 점이 좋아 선택했다. 토크나이저를 사용하지 않는 만큼 추천에 걸리는 시간이 줄어들 것이라 예상했기 때문이다. 

[KR-WordRank, 토크나이저를 이용하지 않는 한국어 키워드 추출기](https://lovit.github.io/nlp/2018/04/16/krwordrank/)

그러나 네이버 게시글 수가 적으면 키워드가 추출되지 않는 에러가 발생할 수 있다. 이럴 땐 명사만 추출해도 어느 정도 키워드를 잡을 수 있을 거라 생각했다. 단, mecab, khaiii 등과 같은 토크나이저로 명사를 추출하기에 네이버 블로그는 맞춤법과 띄어쓰기가 지켜지지 않았다. 그래서 soynlp 토크나이저를 활용하여 명사를 추출했다. 

### 3. 유사도 측정

키워드를 추출했으니, 키워드와 유사한 도서를 찾아야 한다. 

나는 책 소개에서 명사와 형용사만 추출하여 이를 TF-IDF로 벡터화 했다. 어차피 키워드끼리 비교하는 것이기 때문에 단어의 빈도만 고려해도 어느 정도 만족스러운 결과가 나올 거라 예상했다. 


```python
tfidf = TfidfVectorizer()
data = [bookinfo[key]["bookToken"] for key in bookinfo.keys()]
data.append(keywords)
tfidf_matrix = tfidf.fit_transform(data)
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)
title_to_index = dict(zip(data, [n for n in range(len(data))]))
result = get_recommendations(keywords, title_to_index, list(bookinfo.keys()), cosine_sim)
```


우선 각 도서의 책 소개를 data 변수에 넣었다. 이때 책 소개는 앞에서 Okt 토크나이저로 명사/형용사만 추출된 상태이다.

그 다음, 추출한 키워드를 data 변수에 추가했다. 이때 추출한 키워드는 list 형태가 아닌 string 형태이다. 

처음엔 키워드를 따로 처리했다. [소망, 사람, 마음]이라는 키워드가 추출되었으면, 소망과 유사한 도서/ 사람과 유사한 도서 .. 이런 식으로 도서를 추출했다. 그러다 보니 중복된 도서가 많았고 이를 처리하기 위해 또 시간복잡도를 늘리고 싶지 않았다. 

어차피 키워드는 서로 연관성이 있는 단어들이 뽑힌다. 그렇기에 한 문장으로 묶어도 될 것 같았다. 

이후, 사이킷런에서 제공하는 TF-IDF 알고리즘 라이브러리를 활용하여 코사인 유사도를 계산했다. 


### 4. API 배포

사실 머신러닝은 내가 지원하고자 하는 분야가 아니라서 정말 기본적인 알고리즘으로 추천 시스템을 구성했다. 아마 위 알고리즘 보다 더 좋은 도서 추천 알고리즘이 있지 않을까?

아무튼 위에서 만든 알고리즘을 Flask API로 배포하고자 한다. 

API는 다음과 같은 과정으로 진행된다.

Nginix -> uwsgi socket -> Flask

먼저 Nginix 웹 서버로 API를 구동하면 uwsgi socket을 실행하여 Flask API를 작동시킨다. 

사실 Ngnix를 사용한 이유는 리버스 프록시를 사용해보고 싶어서였다. 

```python
CORS(app, resources={r'*': {'origins': '*'}})
CORS(app, resources={r'*': {'origins': 'http://localhost:3000'}})

```

API를 만들면 절대 피할 수 없는 문제가 CORS 정책 문제이다. 지금까지 Flask API에서 CORS 정책을 해결했지만, Ngnix로 해결하면 더 간단할 것 같았다. 

하지만 .. 

GET REST API는 잘 작동하는데 POST REST API는 왜인지 되지 않았다. 

몇일 동안 구글링하며 해결책을 찾지 못했다. 그래서 이번 프로젝트는 어쩔 수 없이 또 Flask에서 CORS 정책을 해결했다 ..

아직 내가 Ngnix 설정이 미숙해서 그런 듯 싶다. 다음 프로젝트에서는 이 문제에 대해 좀 더 심도있게 다뤄야겠다. 

또 HTTPS, HTTP 호환 문제도 있었다. API는 HTTP에서 구동되는데, API를 적용할 페이지는 HTTPS여서 API를 불러오지 못하는 에러였다. 

이또한 몇날 몇일 구글링을 해서 여러가지 해결책을 찾았지만, 해결하지 못했다. 

정말 ..

정말 .. 다음엔 CORS, HTTP/HTTPS 문제 .. 해결해준다 !!! 


## 개발 과정 - 프론트엔드

나는 정말 미적 감각이 없기 때문에 앞서 학습용으로 만들었던 "ToDo 앱"에서 디자인을 가져왔다. 

전반적인 코드는 ToDo 앱과 달라진 것이 없기 때문에 생략한다. 


![ezgif com-gif-maker](https://user-images.githubusercontent.com/78461009/183413533-d7179f1b-6afa-4acf-a8f5-827554346ab3.gif)


어쨌든 ~!

뚝딱거리며 개인 프로젝트를 하나 완성했다. 

도서관 데이터를 다루지 못한 아쉬움과, 나름 백엔드 지망생인데 CORS/HTTP와 같은 기본적인 문제를 해결하지 못한 것에 대해 아쉬움이 남는 프로젝트이다. 

